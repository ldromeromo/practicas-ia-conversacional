{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividades Prácticas\n",
    "1. Configurar entorno de desarrollo python.\n",
    "2. Instalar dependencias 'pip install openai transformers torch'.\n",
    "3. Hola mundo ya sea OpenAI o HuggingFace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  store=True,\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": \"write a haiku about ai\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai  # Importa la biblioteca de OpenAI para interactuar con su API.\n",
    "import os  # Importa la biblioteca os para interactuar con el sistema operativo.\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")  # Configura tu clave API para autenticarte con OpenAI.\n",
    "respuesta = openai.Completion.create(  # Llama a la API de OpenAI para generar texto.\n",
    "    model=\"gpt-4.1-mini\", # Especifica el modelo a utilizar (por ejemplo, text-davinci-003).\n",
    "    prompt=\"Hola, ¿cómo estás?\",  # Define el texto inicial o pregunta para el modelo.\n",
    "    max_tokens=50  # Limita la cantidad máxima de tokens en la respuesta generada.\n",
    ")\n",
    "print(respuesta.choices[0].text.strip())  # Imprime la respuesta generada, eliminando espacios innecesarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# Configura tu API Key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Crea un prompt básico\n",
    "prompt = \"Hola, ¿cómo estás? Escribe un poema corto sobre la inteligencia artificial.\"\n",
    "\n",
    "# Llama a la API\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4.1-mini\",  # puedes usar gpt-4, gpt-4o, gpt-3.5-turbo, etc.\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Eres un asistente útil y conciso.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Imprime la respuesta\n",
    "print(response['choices'][0]['message']['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")  # O ponla directamente aquí si quieres\n",
    "\n",
    "# Listar los modelos disponibles\n",
    "modelos = openai.Model.list()\n",
    "\n",
    "for modelo in modelos.data:\n",
    "    print(modelo.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline  # Importa la función pipeline de la biblioteca Transformers.\n",
    "generador = pipeline(\"text-generation\", model=\"gpt2\")  # Configura un generador de texto usando el modelo GPT-2.\n",
    "texto = generador(\"Hi, ¿How are you?\",  # Genera texto basado en el prompt inicial.\n",
    "    max_length=50,  # Define la longitud máxima del texto generado.\n",
    "    do_sample=True,  # Activa el muestreo para generar texto más variado.\n",
    "    temperature=0.5,  # Controla la aleatoriedad; valores bajos producen texto más coherente.\n",
    "    top_k=50,  # Considera las 50 palabras más probables en cada paso de generación. (OPCIONAL)\n",
    "    top_p=0.95  # Usa el enfoque de muestreo de núcleo para limitar la probabilidad acumulada. (OPCIONAL)\n",
    "    )\n",
    "print(texto[0]['generated_text'])  # Imprime el texto generado por el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline  # Importa la función pipeline de la biblioteca Transformers.\n",
    "generador = pipeline(\"text-generation\", model=\"EleutherAI/gpt-neo-1.3B\")\n",
    "texto_coherente = generador(\n",
    "    \"Hi, ¿How are you?\",\n",
    "    max_length=200,  # Longitud máxima del texto generado\n",
    "    do_sample=True,  # Activa el muestreo\n",
    "    temperature=0.7,  # Reduce la aleatoriedad para mayor coherencia\n",
    "    # top_k=10,  # Considera solo las 10 palabras más probables\n",
    "    # top_p=0.9  # Limita la probabilidad acumulada\n",
    ")\n",
    "print(texto_coherente[0]['generated_text'])  # Imprime el texto generado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "generador = pipeline(\"text-generation\", model=\"EleutherAI/gpt-neo-1.3B\")\n",
    "texto_coherente = generador(\n",
    "    \"Hi, ¿How are you?\",\n",
    "    max_length=50,\n",
    "    do_sample=True,\n",
    "    temperature=0.4,\n",
    ")\n",
    "print(texto_coherente[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "generador = pipeline(\"text-generation\", model=\"EleutherAI/gpt-neo-1.3B\")\n",
    "texto_coherente = generador(\n",
    "    \"Give me two examples of linear equations, without text\",\n",
    "    max_length=200,\n",
    "    do_sample=True,\n",
    "    temperature=0.4,\n",
    ")\n",
    "print(texto_coherente[0]['generated_text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
