{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Ejemplo practivo\n",
    "1. Cargar el modelo y el tonikezer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Model(\n",
       "  (wte): Embedding(50257, 768)\n",
       "  (wpe): Embedding(1024, 768)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (h): ModuleList(\n",
       "    (0-11): 12 x GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D(nf=2304, nx=768)\n",
       "        (c_proj): Conv1D(nf=768, nx=768)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D(nf=3072, nx=768)\n",
       "        (c_proj): Conv1D(nf=768, nx=3072)\n",
       "        (act): NewGELUActivation()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2Model  # Importamos el tokenizer y el modelo GPT-2 desde transformers\n",
    "import torch  # Importamos PyTorch para trabajar con tensores\n",
    "\n",
    "# Cargamos el tokenizer y el modelo base (no el de generación, sino el puro modelo)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")  # Inicializamos el tokenizer preentrenado de GPT-2\n",
    "model = GPT2Model.from_pretrained(\"gpt2\")  # Cargamos el modelo base preentrenado de GPT-2\n",
    "\n",
    "# Ponemos el modelo en modo evaluación para que no calcule gradientes\n",
    "model.eval()  # Configuramos el modelo en modo evaluación\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Tokeniza una palabra y obtiene su ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs: [39, 5708]\n",
      "Primer token ID: 39\n",
      "Token decodificado: H\n"
     ]
    }
   ],
   "source": [
    "# Palabra o frase que quieras analizar\n",
    "texto = \"Hola\"  # Definimos el texto de entrada\n",
    "\n",
    "# Obtenemos los token IDs\n",
    "tokens = tokenizer.encode(texto, add_special_tokens=False)  # Convertimos el texto en IDs de tokens\n",
    "print(\"Token IDs:\", tokens)  # Mostramos los IDs de los tokens\n",
    "\n",
    "# Tomamos el primer token ID\n",
    "token_id = tokens[0]  # Seleccionamos el primer token ID\n",
    "print(\"Primer token ID:\", token_id)  # Mostramos el primer token ID\n",
    "\n",
    "# Mostramos el texto original de ese token\n",
    "print(\"Token decodificado:\", tokenizer.decode([token_id]))  # Decodificamos el token ID para obtener el texto original\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Accede al embedding del token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector de embedding: tensor([[ 7.4618e-02,  5.7276e-02,  2.2950e-01, -2.0877e-02,  1.5292e-02,\n",
      "         -1.0244e-01, -2.1924e-01, -6.3817e-02,  7.5938e-02,  1.6799e-01,\n",
      "         -7.6611e-02, -3.0865e-02,  7.1921e-02, -6.0985e-02, -3.3183e-02,\n",
      "          9.6738e-03,  1.0140e-01,  2.4016e-01,  1.6326e-02,  2.3878e-01,\n",
      "         -9.1324e-02,  5.3105e-02, -1.5359e-01, -6.0741e-02, -7.1321e-02,\n",
      "         -1.5475e-02, -1.2215e-02,  7.0836e-03, -8.6383e-02,  5.5227e-02,\n",
      "         -7.1300e-02, -8.2663e-02, -1.0706e-01,  1.2035e-02, -6.2054e-02,\n",
      "          1.7525e-02, -3.1762e-01, -1.5260e-02,  7.0130e-02, -1.1614e-01,\n",
      "          2.1425e-02, -3.8277e-02,  1.6987e-02, -3.3121e-02,  5.2936e-02,\n",
      "          8.9032e-02,  1.4139e-02, -3.4462e-03,  1.6221e-02, -1.2182e-01,\n",
      "         -8.5824e-02,  6.5456e-02,  1.5971e-01, -5.0398e-02, -1.3756e-01,\n",
      "         -2.3698e-01,  1.5698e-02,  2.3051e-02,  5.8821e-02, -5.4457e-02,\n",
      "         -6.2108e-02,  6.8050e-02,  2.3765e-02,  3.3778e-03, -1.4321e-01,\n",
      "          1.1054e-01,  1.2796e-01, -4.2281e-02,  1.9840e-01, -1.7963e-01,\n",
      "          9.3049e-02,  3.2404e-02, -8.4929e-02, -9.0406e-03,  1.3760e-02,\n",
      "          4.8915e-02, -5.1206e-02,  8.0586e-02,  8.3992e-02, -3.5447e-02,\n",
      "          1.6737e-01,  5.3466e-03, -2.5065e-03, -9.8549e-03,  3.7914e-01,\n",
      "         -1.6857e-01, -1.2297e-01, -1.8661e-01, -1.7459e-01, -2.0150e-01,\n",
      "          8.5613e-02, -7.8390e-03, -5.5926e-02,  1.9983e-03,  6.4660e-02,\n",
      "          4.0229e-02, -4.6640e-03, -1.2906e-02, -2.5982e-02,  4.2818e-02,\n",
      "         -1.4294e-01,  1.0359e-01, -7.7280e-02, -4.2292e-02, -2.6759e-01,\n",
      "          4.3550e-02,  1.2300e-01, -1.2460e-01,  9.8717e-02, -7.1399e-02,\n",
      "          1.1764e-02,  3.4316e-02, -6.0626e-02,  1.4680e-01, -4.0575e-03,\n",
      "          7.3592e-02,  6.8247e-02,  1.2908e-01, -4.7826e-02,  5.6687e-02,\n",
      "          7.5144e-02,  9.7220e-02, -1.2742e-01, -5.2574e-03,  3.9961e-02,\n",
      "         -6.1504e-02,  1.0697e-01,  4.5863e-02, -2.4460e-02, -9.2458e-02,\n",
      "         -5.0648e-02, -1.9265e-01, -1.1359e-01,  1.3943e-01, -8.2681e-02,\n",
      "         -1.1509e-01, -2.2143e-03, -5.8442e-02,  3.5669e-01, -1.2048e-01,\n",
      "          1.1133e-01, -3.9543e-02,  8.4047e-02, -1.1172e-01, -8.2068e-02,\n",
      "         -1.3002e-01,  3.9954e-02, -2.1704e-02,  6.1256e-02, -3.0127e-02,\n",
      "          4.3342e-02, -1.6101e-01,  4.6817e-02, -1.3605e-01,  7.6492e-02,\n",
      "          1.3154e-01,  1.0411e-01, -6.8689e-03,  1.8311e-01,  3.9038e-02,\n",
      "         -4.4617e-02,  1.1147e-01, -1.9827e-01,  8.5488e-02,  1.3460e-01,\n",
      "          5.9525e-02,  5.0405e-02,  2.5093e-01,  1.4991e-01,  3.8721e-02,\n",
      "          7.2587e-02,  9.7283e-02, -3.8146e-02,  7.4474e-02, -1.4942e-02,\n",
      "         -1.0832e-02,  2.7450e-01, -2.4306e-01, -1.7292e-01, -4.8053e-02,\n",
      "         -1.0206e-01,  1.1798e-02,  1.0142e-02, -1.4239e-01, -6.9903e-02,\n",
      "          2.3466e-02,  4.6055e-02, -1.7448e-01, -7.4336e-02, -1.2445e-01,\n",
      "         -1.2500e-01, -1.4933e-02, -5.2160e-02,  1.5399e-02,  5.8386e-02,\n",
      "          1.1587e-01, -8.6152e-02,  9.8871e-02, -4.9166e-02,  9.4645e-02,\n",
      "          4.4530e-03, -8.0738e-02,  9.4714e-02,  2.2421e-02,  3.9442e-02,\n",
      "         -1.2989e-02, -2.1003e-02, -1.0197e-01, -1.8592e-03, -1.8766e-02,\n",
      "          1.4381e-01, -7.1386e-02,  1.3318e-01, -1.5061e-01, -1.2272e-01,\n",
      "          9.5270e-03, -2.5033e-03,  4.3656e-02,  2.0245e-01,  2.3593e-02,\n",
      "          8.9309e-03,  1.5921e-01,  1.0749e-01, -3.1961e-02, -2.7490e-02,\n",
      "         -6.8639e-03,  5.7720e-02,  1.0992e-01, -2.9326e-02,  8.7381e-02,\n",
      "         -6.1783e-02,  6.1842e-02, -2.3781e-01, -1.8731e-01,  6.0903e-02,\n",
      "         -7.1456e-03, -1.0821e-01, -1.1501e-01,  6.3866e-02,  8.8208e-04,\n",
      "         -1.6345e-02,  2.1664e-03, -1.3364e-01, -5.2209e-02, -1.5666e-01,\n",
      "         -1.3518e-01,  1.4484e-01,  2.2133e-02, -8.6856e-02,  1.5229e-01,\n",
      "          1.0357e-01, -7.5028e-03,  4.0433e-02, -4.0472e-02,  9.9361e-02,\n",
      "         -1.0991e-01,  7.6739e-02,  2.1666e-03,  1.2267e-01, -4.6716e-02,\n",
      "         -1.4206e-01,  8.1546e-02,  3.1099e-03,  1.2066e-01, -1.5380e-03,\n",
      "          2.3312e-02, -1.9429e-01, -4.8857e-03,  1.3291e-01, -1.3128e-01,\n",
      "          1.2844e-01, -1.0758e-01, -6.5554e-02, -8.8444e-02, -1.5524e-01,\n",
      "          3.9272e-02, -4.1347e-02,  5.8885e-02, -4.9188e-02, -9.1015e-02,\n",
      "         -6.1086e-02, -1.1425e-01, -1.1469e-01, -6.2071e-03,  3.6226e-02,\n",
      "          4.2855e-02,  1.3997e-01, -4.2140e-02, -2.1102e-01,  9.4998e-02,\n",
      "          7.9343e-02, -5.7504e-02, -4.0494e-02,  1.1449e-01,  1.7323e-01,\n",
      "         -8.4315e-02, -2.1717e-02,  1.7093e-01,  9.2625e-02,  1.1442e-01,\n",
      "         -3.7901e-02, -8.0598e-02, -6.4363e-02, -2.0518e-01,  1.1200e-01,\n",
      "          2.4022e-02,  2.3469e-02, -5.2429e-02,  2.2337e-01,  1.7580e-01,\n",
      "          1.1793e-01,  1.1014e-01,  9.2306e-02, -9.9933e-02,  2.0009e-01,\n",
      "         -3.9746e-02,  1.6349e-02,  1.7713e-01, -1.6844e-01, -7.5840e-02,\n",
      "          2.7648e-01,  6.4639e-02,  1.6274e-01,  2.1632e-01, -1.7846e-01,\n",
      "         -4.6420e-02, -1.3401e-01,  1.3818e-01,  6.2671e-02, -6.0704e-02,\n",
      "         -1.5061e-01,  1.1586e-01, -1.0194e-01,  1.0628e-01, -9.5146e-02,\n",
      "         -5.0772e-02, -3.3048e-02,  1.9358e-01, -6.3648e-02,  4.8695e-02,\n",
      "         -1.0035e-01,  1.5154e-02, -9.9561e-02,  2.6731e-02,  2.0991e-02,\n",
      "         -5.9506e-03, -1.4634e-02, -2.4389e-03,  1.4054e-02, -1.3306e-01,\n",
      "          8.5945e-02, -1.5518e-01,  6.0005e-02, -1.6759e-02, -7.0713e-02,\n",
      "         -9.3476e-02,  1.1749e-01,  1.1297e-02,  3.0349e-02, -1.2166e-01,\n",
      "          6.2319e-02, -1.2149e-02, -5.3710e-01,  5.2710e-04,  3.3249e-02,\n",
      "          1.4949e-01, -8.6584e-02,  7.1259e-02, -1.7755e-02, -1.9964e-01,\n",
      "          2.4299e-03,  9.8405e-02,  2.9280e-02, -1.2664e-01,  1.7830e-01,\n",
      "          6.5170e-02, -3.7942e-03, -1.1997e-01, -4.9087e-02, -4.3824e-02,\n",
      "          2.2635e-02,  1.6905e-01, -1.5311e-01, -8.5642e-02,  1.9981e-02,\n",
      "         -8.4336e-02, -1.6705e-01, -1.7618e-01,  4.5439e-02,  4.1882e-02,\n",
      "          1.1935e-02, -4.9956e-02,  1.4159e-01, -2.0990e-01, -8.8680e-02,\n",
      "          2.0869e-02, -7.2659e-03,  3.5010e-02,  2.0203e-01, -9.3846e-03,\n",
      "          4.0600e-02, -4.1213e-02, -6.9701e-02, -1.0982e-02,  2.1821e-02,\n",
      "          2.2473e-02,  5.7513e-02,  1.0618e-01, -3.7533e-01, -1.4634e-01,\n",
      "          7.7036e-02, -9.4485e-02,  3.1287e-02,  6.4468e-02,  5.2257e-02,\n",
      "          1.6315e-01, -8.4734e-02,  8.8258e-02, -4.7864e-03, -7.2642e-02,\n",
      "          4.4493e-02, -6.6366e-03, -1.0834e-01, -2.8787e-02, -7.3256e-03,\n",
      "          1.3109e-01, -8.9394e-02, -4.3443e-02,  1.2806e-01,  9.5670e-02,\n",
      "         -2.5556e-01, -3.6165e-03,  7.4294e-02,  4.5959e-02,  2.0411e-01,\n",
      "         -5.4219e-02, -8.5349e-02, -6.4006e-02,  6.9968e-03, -1.3776e-01,\n",
      "         -1.2499e-01, -3.1902e-02, -1.5130e-01, -9.9050e-03, -1.1107e-01,\n",
      "         -3.8767e-02,  6.9802e-02,  1.5204e-01, -1.1861e-01,  1.4353e-01,\n",
      "         -3.0190e-02, -5.6266e-02,  1.2594e-01,  1.5699e-01, -2.1864e-02,\n",
      "         -1.4508e-01,  1.5971e-01,  1.2573e-01, -4.4262e-02, -9.6587e-02,\n",
      "         -8.5013e-02, -2.6172e-02, -1.6281e-01, -1.7727e-01,  6.7341e-02,\n",
      "          1.5426e-01,  1.4395e-01, -3.7862e-02, -1.9072e-01, -4.9410e-02,\n",
      "         -1.0811e-01,  1.3029e-01,  9.6068e-02, -1.9979e-02,  1.2483e-01,\n",
      "         -9.6390e-02, -6.6687e-02,  1.4916e-01, -1.2763e-03,  2.3546e-01,\n",
      "         -2.2454e-01,  1.0290e-01,  2.3095e-02, -1.7054e-01, -1.1713e-01,\n",
      "         -7.2121e-02, -1.6610e-02,  2.1709e-01, -4.2162e-02,  9.6317e-02,\n",
      "          4.0057e-02, -2.4742e-03,  1.0459e-01,  1.4698e-01,  2.4918e-02,\n",
      "         -1.3062e-03, -2.0557e-01,  4.4152e-02, -1.4145e-01, -5.3845e-02,\n",
      "         -7.5993e-02, -6.9798e-02, -3.4526e-02,  1.5297e-01,  3.8936e-02,\n",
      "          9.0410e-03, -4.4684e-02, -2.7729e-02,  4.0878e-02, -3.1719e-02,\n",
      "          8.9353e-02,  1.7462e-01, -1.4502e-01,  2.9060e-02, -4.7523e-02,\n",
      "         -3.3965e-02, -5.0787e-02, -5.0895e-02,  3.8192e-02,  5.6365e-04,\n",
      "         -1.4611e-01, -1.3416e-01,  1.5029e-02, -5.9385e-02,  5.3507e-02,\n",
      "         -1.8570e-02,  6.4024e-02,  4.0940e-01, -4.0284e-02, -9.9788e-02,\n",
      "         -2.3263e-02, -8.1834e-02,  2.4324e-02,  2.0591e-01, -4.5008e-02,\n",
      "         -1.0522e-03, -9.0586e-02, -1.2115e-01,  8.1781e-02,  2.6402e-02,\n",
      "         -8.5054e-02,  2.1660e-01, -1.0132e-01,  1.7692e-01,  9.8422e-02,\n",
      "         -6.9077e-02,  1.0011e-01, -1.3647e-01, -2.9256e-02, -1.1999e-01,\n",
      "         -1.5292e-01, -1.1748e-01, -8.2856e-02,  6.0205e-02,  1.8326e-01,\n",
      "         -1.1412e-01, -1.1642e-02, -6.5857e-02, -9.6686e-02,  7.2121e-02,\n",
      "          3.0084e-02, -5.9454e-02, -8.4036e-02,  1.1852e-01, -1.1201e-01,\n",
      "          5.2145e-02, -1.1595e-02,  6.2695e-02, -1.3667e-01,  1.9039e-01,\n",
      "         -3.3968e-02,  3.7172e-02,  1.4700e-02, -8.9758e-04,  1.1522e-01,\n",
      "         -6.1025e-02,  1.5960e-01,  1.8474e-01,  9.2113e-02,  1.3518e-01,\n",
      "         -3.6021e-02,  1.5309e-02,  1.6953e-02, -8.6240e-02,  4.0634e-02,\n",
      "          4.0250e-02,  1.2663e-01, -7.4936e-02, -1.3402e-01,  1.7679e-01,\n",
      "         -1.3747e-01, -1.5881e-02, -1.0268e-01, -3.5874e-02,  7.6700e-03,\n",
      "         -5.1471e-02, -4.1310e-02,  7.8298e-02, -4.3913e-02, -7.9810e-02,\n",
      "          9.1186e-02, -6.3142e-02,  2.0233e-01, -3.3773e-02, -1.1393e-01,\n",
      "          1.0948e-01, -1.0578e-01,  8.8781e-02, -3.6147e-01, -1.1657e-01,\n",
      "          5.5206e-02, -9.9018e-02, -8.8971e-02, -3.8432e-02, -1.4893e-01,\n",
      "         -7.5360e-02, -6.7279e-02, -2.4886e-02,  4.0158e-03, -3.4415e-02,\n",
      "         -1.1676e-01, -1.1336e-01, -2.0841e-01,  4.2212e-02, -3.1059e-03,\n",
      "         -1.1492e-02,  1.7559e-01,  2.7005e-01, -8.5448e-02,  1.8452e-02,\n",
      "         -1.1910e-01,  1.4009e-01,  5.1392e-02, -8.4274e-02,  1.0250e-01,\n",
      "          2.9776e-01, -7.5310e-02, -1.2469e-01, -5.0358e-02,  1.5173e-02,\n",
      "         -3.0015e-03,  1.7720e-01,  5.6212e-02, -2.3484e-02, -1.9027e-02,\n",
      "          9.6699e-02,  2.5824e-02, -8.4284e-02,  1.3223e-01,  3.4741e-01,\n",
      "          1.6607e-01, -5.2647e-02,  9.1306e-02, -4.5896e-02,  6.5798e-02,\n",
      "         -1.6649e-01,  9.8181e-02, -3.8773e-02, -5.1011e-02, -1.0250e-01,\n",
      "          9.9040e-03,  8.4698e-02,  1.7067e-01, -5.0098e-02,  9.9045e-02,\n",
      "         -2.1426e-02, -2.5654e-03, -3.9404e-02, -2.5679e-01,  3.0771e-02,\n",
      "          1.6757e-01,  2.4388e-01, -3.4468e-02,  4.4013e-02, -5.3674e-02,\n",
      "          1.4449e-02, -2.4220e-02,  5.2534e-03, -6.0527e-02, -1.7792e-01,\n",
      "          3.2393e-02,  1.0112e-01,  6.9933e-02,  1.0306e-01, -1.4943e-01,\n",
      "          4.3619e-02,  2.5523e-02,  1.3929e-01, -9.2632e-02, -7.4301e-02,\n",
      "         -7.5281e-02, -1.4027e-03,  3.6665e-02, -2.0822e-02,  2.1425e-01,\n",
      "         -1.4023e-01,  7.0620e-02,  9.9763e-02, -4.0197e-02, -2.0554e-02,\n",
      "         -2.0300e-02,  3.6614e-02,  2.9211e-02,  1.4794e-01,  7.6067e-02,\n",
      "          1.5589e-02,  2.0790e-01, -3.4856e-02, -6.6762e-03,  1.7862e-01,\n",
      "         -1.1858e-02, -5.0309e-02, -7.1452e-02, -5.4276e-02, -1.4291e-02,\n",
      "         -6.0552e-02,  1.5968e-01,  9.7900e-02,  1.3589e-02,  6.1672e-02,\n",
      "         -6.0997e-02,  1.8855e-01,  2.6852e-02, -7.9779e-02, -5.1289e-02,\n",
      "         -1.0185e-01, -2.0204e-01,  1.1904e-01,  1.2681e-01,  7.0744e-02,\n",
      "         -8.0324e-02, -6.8483e-02,  1.3954e-02, -1.5014e-02,  5.9445e-02,\n",
      "          1.2981e-01, -1.1307e-02, -9.0399e-02, -7.3259e-02,  2.6983e-01,\n",
      "          8.3615e-02, -7.0381e-02,  6.8549e-02, -3.9601e-03,  1.9886e-01,\n",
      "          1.3596e-01, -1.1125e-01,  2.5184e-02,  6.8420e-02, -6.7615e-03,\n",
      "         -6.7973e-02,  4.7619e-02, -2.0024e-02,  9.5707e-02,  3.8658e-02,\n",
      "         -4.4780e-02, -4.4817e-02, -1.2426e-01, -1.4852e-01, -2.8589e-02,\n",
      "          4.7886e-02,  2.2039e-01, -2.4653e-01, -9.5358e-02,  1.5761e-01,\n",
      "         -1.2535e-01, -5.0558e-02, -1.6396e-01]], grad_fn=<EmbeddingBackward0>)\n",
      "Dimensión del vector: torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "# Convertimos el token ID a un tensor de PyTorch\n",
    "token_tensor = torch.tensor([token_id])  # Creamos un tensor a partir del token ID\n",
    "\n",
    "# Accedemos a la capa de embeddings del modelo\n",
    "embedding_layer = model.get_input_embeddings()  # Obtenemos la capa de embeddings del modelo\n",
    "\n",
    "# Obtenemos el vector de embedding del token\n",
    "embedding_vector = embedding_layer(token_tensor)  # Calculamos el vector de embedding para el token\n",
    "\n",
    "# Mostramos el vector\n",
    "print(\"Vector de embedding:\", embedding_vector)  # Imprimimos el vector de embedding\n",
    "print(\"Dimensión del vector:\", embedding_vector.shape)  # Esperamos torch.Size([1, 768])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Visualiza los primeros valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeros 10 valores: [ 0.07461753  0.05727639  0.22950119 -0.02087739  0.01529151 -0.10244091\n",
      " -0.21923806 -0.06381667  0.07593805  0.16798739]\n"
     ]
    }
   ],
   "source": [
    "# Mostrar los primeros 10 valores del embedding\n",
    "print(\"Primeros 10 valores:\", embedding_vector[0][:10].detach().numpy())  # Mostramos los primeros 10 valores del vector de embedding\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
